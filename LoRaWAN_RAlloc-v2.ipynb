{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import simpy\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, MaxPooling2D, Activation, Flatten\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# from gym.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Config\n",
    "# log-distance loss model parameters\n",
    "\n",
    "PTX = 14.0\n",
    "GAMMA = 2.08\n",
    "D0 = 40.0\n",
    "VAR = 0  # variance ignored for now\n",
    "LPLD0 = 127.41\n",
    "\n",
    "# Gate way localisation\n",
    "BSX = 0.0\n",
    "BSY = 0.0\n",
    "HM = 1.0  # m\n",
    "HB = 15.0  # m\n",
    "\n",
    "RAY = 700.0\n",
    "\n",
    "# Created Nodes\n",
    "NODES = []\n",
    "\n",
    "packetlen = 20\n",
    "\n",
    "\n",
    "BW = 125\n",
    "PL = 20\n",
    "CR = 1\n",
    "\n",
    "p = 300\n",
    "AVGSENDTIME = p\n",
    "# Inter-SF Thresshold Mateix\n",
    "\n",
    "IS7 = np.array([6, -8, -9, -9, -9, -9])\n",
    "IS8 = np.array([-11, 6, -11, -12, -13, -13])\n",
    "IS9 = np.array([-15, -13, 6, -13, -14, -15])\n",
    "IS10 = np.array([-19, -18, -17, 6, -17, -18])\n",
    "IS11 = np.array([-22, -22, -21, -20, 6, -20])\n",
    "IS12 = np.array([-25, -25, -25, -24, -23, 6])\n",
    "SIR = np.array([IS7, IS8, IS9, IS10, IS11, IS12])\n",
    "\n",
    "\n",
    "config_dict = {\n",
    "    0: {\"sf\": 7, \"sens\": -126.5, \"snr\": -7.5},\n",
    "    1: {\"sf\": 8, \"sens\": -127.25, \"snr\": -10},\n",
    "    2: {\"sf\": 9, \"sens\": -131.25, \"snr\": -12.5},\n",
    "    3: {\"sf\": 10, \"sens\": -132.75, \"snr\": -15},\n",
    "    4: {\"sf\": 11, \"sens\": -133.25, \"snr\": -17.5},\n",
    "    5: {\"sf\": 12, \"sens\": -134.5, \"snr\": -20},\n",
    "}\n",
    "\n",
    "ch = [868100000, 868300000, 868500000]\n",
    "tpx = [2, 5, 8, 11, 14]\n",
    "MODEL = 6\n",
    "SEED = 913\n",
    "\n",
    "rho_max = 0.5\n",
    "tp_max = 14\n",
    "tp_min = 2\n",
    "\n",
    "N = 1000\n",
    "\n",
    "\n",
    "TX = [\n",
    "    22,\n",
    "    22,\n",
    "    22,\n",
    "    23,  # RFO/PA0: -2..1\n",
    "    24,\n",
    "    24,\n",
    "    24,\n",
    "    25,\n",
    "    25,\n",
    "    25,\n",
    "    25,\n",
    "    26,\n",
    "    31,\n",
    "    32,\n",
    "    34,\n",
    "    35,\n",
    "    44,  # PA_BOOST/PA1: 2..14\n",
    "    82,\n",
    "    85,\n",
    "    90,  # PA_BOOST/PA1: 15..17\n",
    "    105,\n",
    "    115,\n",
    "    125,\n",
    "]  # PA_BOOST/PA1+PA2: 18..20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def SF_alloc_ch_utilization(NODES):\n",
    "    sorted_nodes = []\n",
    "    sorted_nodes = sorted(NODES, key=lambda x: x.dist, reverse=False)\n",
    "    c_class = np.zeros(6, dtype=int)\n",
    "    ch_len = len(ch)\n",
    "    ch_u = np.zeros(ch_len, dtype=int)\n",
    "    # print(c_class)\n",
    "    for n in sorted_nodes:\n",
    "        sf = n.sf\n",
    "        # print(sf)\n",
    "        config = config_dict[sf - 7]\n",
    "        # print(config)\n",
    "        for i in range(sf, 12):\n",
    "            if n.snr < config[\"snr\"] or n.rssi < config[\"sens\"]:\n",
    "                if n.sf < 12:\n",
    "                    n.sf = n.sf + 1\n",
    "                    n.packet.sf = n.sf\n",
    "                    n.update_rectime(n.sf)\n",
    "            config = config_dict[n.sf - 7]\n",
    "        c_class[n.sf - 7] = c_class[n.sf - 7] + 1\n",
    "        ch_index = ch.index(n.freq)\n",
    "        ch_u[ch_index] = ch_u[ch_index] + 1\n",
    "    return sorted_nodes, c_class, ch_u\n",
    "\n",
    "\n",
    "def compute_sf_ch_utilization(nodes):\n",
    "    sf_dist = np.zeros(6, dtype=int)\n",
    "    tp_dist = np.zeros(5, dtype=int)\n",
    "    ch_len = len(ch)\n",
    "    ch_dist = np.zeros(ch_len, dtype=int)\n",
    "    # print(ch_dist)\n",
    "    # print(ch_len)\n",
    "    # print_nodes(nodes)\n",
    "    for n in nodes:\n",
    "        sf = n.sf\n",
    "        freq = n.freq\n",
    "        tx = n.tx\n",
    "        sf_dist[sf - 7] = sf_dist[sf - 7] + 1\n",
    "        tp_index = tpx.index(tx)\n",
    "        # print('index',tp_index)\n",
    "        tp_dist[tp_index] = tp_dist[tp_index] + 1\n",
    "\n",
    "        # print('Channel : ',freq)\n",
    "        ch_index = ch.index(freq)\n",
    "        # print('index',ch_index)\n",
    "        ch_dist[ch_index] = ch_dist[ch_index] + 1\n",
    "    return sf_dist, tp_dist, ch_dist\n",
    "\n",
    "\n",
    "def energy_consumption(nodes):\n",
    "    energy = (\n",
    "        sum(\n",
    "            node.packet.rectime * TX[int(node.tx) + 2] * 3 * node.sent for node in nodes\n",
    "        )\n",
    "        / 1e6\n",
    "    )\n",
    "    return energy\n",
    "\n",
    "\n",
    "def print_nodes(nodes):\n",
    "    for n in nodes:\n",
    "        print(\"node_id: {} SF: {} TP: {} CH: {} RSSI: {} SNR: {}\".format(n.id, n.sf, n.tx, n.freq,n.rssi,n.snr))\n",
    "\n",
    "\n",
    "def reward_plot(rewards):\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Packet:\n",
    "    def __init__(self, nodeid, sf, bw, freq, rssi, rectime):\n",
    "        self.nodeid = nodeid\n",
    "        self.pl = packetlen\n",
    "        self.arriveTime = 0\n",
    "        # Reception Parameters\n",
    "        self.sf = sf\n",
    "        self.bw = bw\n",
    "        self.freq = freq\n",
    "        self.rssi = rssi\n",
    "        self.rectime = rectime\n",
    "        self.collided = 0\n",
    "        self.processed = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "class Device:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        self.dist = 0\n",
    "        found = False\n",
    "        while not found:\n",
    "            a = random.random()\n",
    "            b = random.random()\n",
    "            if b < a:\n",
    "                a, b = b, a\n",
    "            posx = b * RAY * math.cos(2 * math.pi * a / b) + BSX\n",
    "            posy = b * RAY * math.sin(2 * math.pi * a / b) + BSY\n",
    "            if len(NODES) > 0:\n",
    "                for index, n in enumerate(NODES):\n",
    "                    dist = np.sqrt(((abs(n.x - posx)) ** 2) + ((abs(n.y - posy)) ** 2))\n",
    "                    if dist >= 20:\n",
    "                        found = 1\n",
    "                        self.x = posx\n",
    "                        self.y = posy\n",
    "                        break\n",
    "            else:\n",
    "                self.x = posx\n",
    "                self.y = posy\n",
    "                found = True\n",
    "\n",
    "        dist_2d = np.sqrt(\n",
    "            (self.x - BSX) * (self.x - BSX) + (self.y - BSY) * (self.y - BSY)\n",
    "        )\n",
    "        # self.dist = np.sqrt((dist_2d)**2+(HB-HM)**2)\n",
    "        self.dist = dist_2d\n",
    "        # Radio Parameters\n",
    "        self.bw = BW\n",
    "        self.sf = 7\n",
    "        self.tx = PTX\n",
    "        self.cr = 1\n",
    "        self.freq = random.choice(ch)\n",
    "        # self.freq = 868100000\n",
    "        self.rssi = self.tx - self.estimatePathLoss(MODEL)\n",
    "        self.snr = random.randrange(-10, 20)\n",
    "        self.rectime = self.airtime(self.sf, self.cr, packetlen, BW)\n",
    "        self.packet = Packet(\n",
    "            self.id, self.sf, self.bw, self.freq, self.rssi, self.rectime\n",
    "        )\n",
    "        self.sent = 0\n",
    "        self.received = 0\n",
    "\n",
    "    def airtime(self, sf, cr, pl, bw):\n",
    "        H = 0  # implicit header disabled (H=0) or not (H=1)\n",
    "        DE = 0  # low data rate optimization enabled (=1) or not (=0)\n",
    "        Npream = 8  # number of preamble symbol (12.25  from Utz paper)\n",
    "\n",
    "        if bw == 125 and sf in [11, 12]:\n",
    "            # low data rate optimization mandated for BW125 with SF11 and SF12\n",
    "            DE = 1\n",
    "        if sf == 6:\n",
    "            # can only have implicit header with SF6\n",
    "            H = 1\n",
    "        Tsym = (2.0 ** sf) / bw  # msec\n",
    "        Tpream = (Npream + 4.25) * Tsym\n",
    "        # print \"sf\", sf, \" cr\", cr, \"pl\", pl, \"bw\", bw\n",
    "        payloadSymbNB = 8 + max(\n",
    "            math.ceil((8.0 * pl - 4.0 * sf + 28 + 16 - 20 * H) / (4.0 * (sf - 2 * DE)))\n",
    "            * (cr + 4),\n",
    "            0,\n",
    "        )\n",
    "        Tpayload = payloadSymbNB * Tsym\n",
    "        return (Tpream + Tpayload) / 1000.0  # in seconds\n",
    "\n",
    "    def log_distance_loss(self, dist):\n",
    "        Lpl = LPLD0 + 10 * GAMMA * math.log10(dist / D0)\n",
    "        rssi = PTX - Lpl\n",
    "        return rssi\n",
    "\n",
    "    def update_rectime(self, sf):\n",
    "        self.rectime = self.airtime(sf, self.cr, packetlen, BW)\n",
    "        self.packet.rectime = self.rectime\n",
    "\n",
    "    def estimatePathLoss(self, model):\n",
    "        # Log-Distance model\n",
    "        if model == 0:\n",
    "            Lpl = LPLD0 + 10 * GAMMA * math.log10(self.dist / D0)\n",
    "\n",
    "        # Okumura-Hata model\n",
    "        elif model >= 1 and model <= 4:\n",
    "            # small and medium-size cities\n",
    "            if model == 1:\n",
    "                ahm = (\n",
    "                    1.1 * (math.log10(self.freq) - math.log10(1000000)) - 0.7\n",
    "                ) * HM - (1.56 * (math.log10(self.freq) - math.log10(1000000)) - 0.8)\n",
    "\n",
    "                C = 0\n",
    "            # metropolitan areas\n",
    "            elif model == 2:\n",
    "                if self.freq <= 200000000:\n",
    "                    ahm = 8.29 * ((math.log10(1.54 * HM)) ** 2) - 1.1\n",
    "                elif self.freq >= 400000000:\n",
    "                    ahm = 3.2 * ((math.log10(11.75 * HM)) ** 2) - 4.97\n",
    "                C = 0\n",
    "            # suburban enviroments\n",
    "            elif model == 3:\n",
    "                ahm = (\n",
    "                    1.1 * (math.log10(self.freq) - math.log10(1000000)) - 0.7\n",
    "                ) * HM - (1.56 * (math.log10(self.freq) - math.log10(1000000)) - 0.8)\n",
    "\n",
    "                C = -2 * ((math.log10(self.freq) - math.log10(28000000)) ** 2) - 5.4\n",
    "            # rural area\n",
    "            elif model == 4:\n",
    "                ahm = (\n",
    "                    1.1 * (math.log10(self.freq) - math.log10(1000000)) - 0.7\n",
    "                ) * HM - (1.56 * (math.log10(self.freq) - math.log10(1000000)) - 0.8)\n",
    "\n",
    "                C = (\n",
    "                    -4.78 * ((math.log10(self.freq) - math.log10(1000000)) ** 2)\n",
    "                    + 18.33 * (math.log10(self.freq) - math.log10(1000000))\n",
    "                    - 40.98\n",
    "                )\n",
    "\n",
    "            A = (\n",
    "                69.55\n",
    "                + 26.16 * (math.log10(self.freq) - math.log10(1000000))\n",
    "                - 13.82 * math.log(HB)\n",
    "                - ahm\n",
    "            )\n",
    "\n",
    "            B = 44.9 - 6.55 * math.log10(HB)\n",
    "\n",
    "            Lpl = A + B * (math.log10(self.dist) - math.log10(1000)) + C\n",
    "\n",
    "        # 3GPP model\n",
    "        elif model >= 5 and model < 7:\n",
    "            # Suburban Macro\n",
    "            if model == 5:\n",
    "                C = 0  # dB\n",
    "            # Urban Macro\n",
    "            elif model == 6:\n",
    "                C = 3  # dB\n",
    "\n",
    "            Lpl = (\n",
    "                (44.9 - 6.55 * math.log10(HB))\n",
    "                * (math.log10(self.dist) - math.log10(1000))\n",
    "                + 45.5\n",
    "                + (35.46 - 1.1 * HM) * (math.log10(self.freq) - math.log10(1000000))\n",
    "                - 13.82 * math.log10(HM)\n",
    "                + 0.7 * HM\n",
    "                + C\n",
    "            )\n",
    "\n",
    "        # Polynomial 3rd degree\n",
    "        elif model == 7:\n",
    "            p1 = -5.491e-06\n",
    "            p2 = 0.002936\n",
    "            p3 = -0.5004\n",
    "            p4 = -70.57\n",
    "\n",
    "            Lpl = (\n",
    "                p1 * math.pow(self.dist, 3)\n",
    "                + p2 * math.pow(self.dist, 2)\n",
    "                + p3 * self.dist\n",
    "                + p4\n",
    "            )\n",
    "\n",
    "        # Polynomial 6th degree\n",
    "        elif model == 8:\n",
    "            p1 = 3.69e-12\n",
    "            p2 = 5.997e-11\n",
    "            p3 = -1.381e-06\n",
    "            p4 = 0.0005134\n",
    "            p5 = -0.07318\n",
    "            p6 = 4.254\n",
    "            p7 = -171\n",
    "\n",
    "            Lpl = (\n",
    "                p1 * math.pow(self.dist, 6)\n",
    "                + p2 * math.pow(self.dist, 5)\n",
    "                + p3 * math.pow(self.dist, 4)\n",
    "                + p4 * math.pow(self.dist, 3)\n",
    "                + p5 * math.pow(self.dist, 2)\n",
    "                + p6 * self.dist\n",
    "                + p7\n",
    "            )\n",
    "\n",
    "        return Lpl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Collision Detection ################\n",
    "\"\"\"\n",
    "\n",
    "This Part Allows Collision Checking Between Two Packets :\n",
    " 1- Timing Collision\n",
    " 2- Frequency Collision\n",
    " 3- SF Collision\n",
    " 4- Capture Effect\n",
    " 5- Imperfect SF Orthogonality\n",
    " \n",
    "\"\"\"\n",
    "########################### 1-Timining Collision #################\n",
    "\n",
    "\n",
    "def timingCollision(env, p1, p2):\n",
    "    Npream = 8\n",
    "    Tpreamb = 2 ** p1.sf / (1.0 * p1.bw) * (Npream - 5)\n",
    "    p2_end = p2.addTime + p2.rectime\n",
    "\n",
    "    p1_cs = env.now + (Tpreamb / 1000.0)  # to sec\n",
    "\n",
    "    \"\"\" print (\"collision timing node {} ({},{},{}) node {} ({},{})\".format(\n",
    "        p1.nodeid, env.now - env.now, p1_cs - env.now, p1.rectime,\n",
    "        p2.nodeid, p2.addTime - env.now, p2_end - env.now\n",
    "    ))\"\"\"\n",
    "    if p1_cs < p2_end:\n",
    "        # p1 collided with p2 and lost\n",
    "        # print (\"not late enough\")\n",
    "        return True\n",
    "    # print (\"saved by the preamble\")\n",
    "    return False\n",
    "\n",
    "\n",
    "######################### 2-Frequency Collision #######################\n",
    "def frequencyCollision(p1, p2):\n",
    "    if abs(p1.freq - p2.freq) <= 120 and (p1.bw == 500 or p2.freq == 500):\n",
    "        # print (\"frequency coll 500\")\n",
    "        return True\n",
    "    elif abs(p1.freq - p2.freq) <= 60 and (p1.bw == 250 or p2.freq == 250):\n",
    "        # print( \"frequency coll 250\")\n",
    "        return True\n",
    "    else:\n",
    "        if abs(p1.freq - p2.freq) <= 30:\n",
    "            # print (\"frequency coll 125\")\n",
    "            return True\n",
    "        # else:\n",
    "    # print (\"no frequency coll\")\n",
    "    return False\n",
    "\n",
    "\n",
    "####################### 3- SF Collision ###############################\n",
    "def sfCollision(p1, p2):\n",
    "    if p1.sf == p2.sf:\n",
    "        # print (\"collision sf node {} and node {}\".format(p1.nodeid, p2.nodeid))\n",
    "        return True\n",
    "    # print (\"no sf collision\")\n",
    "    return False\n",
    "\n",
    "\n",
    "####################### 4-5 ############################################\n",
    "def powerCollision_2(p1, p2):\n",
    "    # powerThreshold = 6\n",
    "    # print (\"SF: node {0.nodeid} {0.sf} node {1.nodeid} {1.sf}\".format(p1, p2))\n",
    "    # print (\"pwr: node {0.nodeid} {0.rssi:3.2f} dBm node {1.nodeid} {1.rssi:3.2f} dBm; diff {2:3.2f} dBm\".format(p1, p2, round(p1.rssi - p2.rssi,2)))\n",
    "\n",
    "    if p1.sf == p2.sf:\n",
    "\n",
    "        if abs(p1.rssi - p2.rssi) < 6:\n",
    "            # print (\"collision pwr both node {} and node {}\".format(p1.nodeid, p2.nodeid))\n",
    "            # packets are too close to each other, both collide\n",
    "            # return both packets as casualties\n",
    "            \"\"\"print(\n",
    "                \"power coll  cap : freq 1 : {} and freq 2 :{} ==> |{}| < {}\".format(\n",
    "                    p1.freq, p2.freq, abs(p1.rssi - p2.rssi), SIR[p1.sf - 7][p2.sf - 7]\n",
    "                )\n",
    "            )\"\"\"\n",
    "            return (p1, p2)\n",
    "        elif p1.rssi - p2.rssi < 6:\n",
    "            # p2 overpowered p1, return p1 as casualty\n",
    "            # print (\"collision pwr node {} overpowered node {}\".format(p2.nodeid, p1.nodeid))\n",
    "            # print (\"capture - p2 wins, p1 lost\")\n",
    "            \"\"\"print(\n",
    "                \"power coll  cap : freq 1 : {} and freq 2 :{}  => {} < {}\".format(\n",
    "                    p1.freq, p2.freq, p1.rssi - p2.rssi, SIR[p1.sf - 7][p2.sf - 7]\n",
    "                )\n",
    "            )\"\"\"\n",
    "            return (p1,)\n",
    "        # print (\"capture - p1 wins, p2 lost\")\n",
    "        # p2 was the weaker packet, return it as a casualty\n",
    "        \"\"\"print(\n",
    "            \"power coll  cap : freq 1 : {} and freq 2 :{} => {} > {}\".format(\n",
    "                p1.freq, p2.freq, p1.rssi - p2.rssi, SIR[p1.sf - 7][p2.sf - 7]\n",
    "            )\n",
    "        )\"\"\"\n",
    "        return (p2,)\n",
    "    else:\n",
    "\n",
    "        if p1.rssi - p2.rssi > SIR[p1.sf - 7][p2.sf - 7]:\n",
    "\n",
    "            # print (\"P1 is OK\")\n",
    "            if p2.rssi - p1.rssi > SIR[p2.sf - 7][p1.sf - 7]:\n",
    "                # print (\"p2 is OK\")\n",
    "                return ()\n",
    "            else:\n",
    "                # print (\"p2 is lost\")\n",
    "                # print(\"power coll  Imp : 2\")\n",
    "                return (p2,)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # print (\"p1 is lost\")\n",
    "            if p2.rssi - p1.rssi > SIR[p2.sf - 7][p1.sf - 7]:\n",
    "\n",
    "                # print (\"p2 is OK\")\n",
    "                # print(\"power coll  Imp : 1\")\n",
    "                return (p1,)\n",
    "            else:\n",
    "                # print (\"p2 is lost\")\n",
    "                # print(\"opwer coll  cap : 1\")\n",
    "                return (p1, p2)\n",
    "\n",
    "\n",
    "######################## Check Collision ############################\n",
    "def checkcollision(env, packet, packetsAtBS, maxBSReceives, full_collision):\n",
    "    col = 0  # flag needed since there might be several collisions for packet\n",
    "    processing = 0\n",
    "    for i in range(0, len(packetsAtBS)):\n",
    "        if packetsAtBS[i].packet.processed == 1:\n",
    "            processing = processing + 1\n",
    "    if processing > maxBSReceives:\n",
    "        # print (\"too long:\", len(packetsAtBS))\n",
    "        packet.processed = 0\n",
    "    else:\n",
    "        packet.processed = 1\n",
    "\n",
    "    if packetsAtBS:\n",
    "        # print (\"CHECK node {} (sf:{} bw:{} freq:{:.6e}) others: {}\".format(\n",
    "        # packet.nodeid, packet.sf, packet.bw, packet.freq,\n",
    "        # len(packetsAtBS)))\n",
    "        # print(len(packetsAtBS))\n",
    "        for other in packetsAtBS:\n",
    "\n",
    "            if other.id != packet.nodeid:\n",
    "                # print (\">> node {} (sf:{} bw:{} freq:{:.6e})\".format(\n",
    "                # other.id, other.packet.sf, other.packet.bw, other.packet.freq))\n",
    "                if full_collision == 1 or full_collision == 2:\n",
    "\n",
    "                    if frequencyCollision(packet, other.packet) and timingCollision(\n",
    "                        env, packet, other.packet\n",
    "                    ):\n",
    "                        # check who collides in the power domain\n",
    "                        if full_collision == 1:\n",
    "                            # Capture effect\n",
    "                            c = powerCollision_2(packet, other.packet)\n",
    "                        else:\n",
    "                            # Capture + Non-orthognalitiy SFs effects\n",
    "                            c = powerCollision_2(packet, other.packet)\n",
    "                        # mark all the collided packets\n",
    "                        # either this one, the other one, or both\n",
    "                        for p in c:\n",
    "                            p.collided = 1\n",
    "                            if p == packet:\n",
    "                                col = 1\n",
    "\n",
    "                    else:\n",
    "                        # no freq or timing collision, all fimone\n",
    "                        pass\n",
    "                else:\n",
    "                    # simple collision\n",
    "                    if frequencyCollision(packet, other.packet) and sfCollision(\n",
    "                        packet, other.packet\n",
    "                    ):\n",
    "                        packet.collided = 1\n",
    "                        other.packet.collided = (\n",
    "                            1  # other also got lost, if it wasn't lost already\n",
    "                        )\n",
    "                        col = 1\n",
    "        return col\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Node generation and Plot Function\n",
    "\n",
    "\n",
    "def node_Gen(nrNodes, display):\n",
    "    NODES = []\n",
    "    x = []\n",
    "    y = []\n",
    "    rssi = []\n",
    "    dist = []\n",
    "\n",
    "    for i in range(nrNodes):\n",
    "        device = Device(i)\n",
    "        NODES.append(device)\n",
    "\n",
    "        x.append(NODES[i].x)\n",
    "        y.append(NODES[i].y)\n",
    "        rssi.append(NODES[i].rssi)\n",
    "        dist.append(NODES[i].dist)\n",
    "    pickle.dump(NODES, open(\"data/nodes.p\", \"wb\"))\n",
    "    if display:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(x, y, \"ro\")\n",
    "        ax.plot(0, 0, \"bo\")\n",
    "        for i in range(6):\n",
    "            v1 = np.linspace((-RAY / 6) * (i + 1), (RAY / 6) * (i + 1), 100)\n",
    "            v2 = np.linspace((-RAY / 6) * (i + 1), (RAY / 6) * (i + 1), 100)\n",
    "            X, Y = np.meshgrid(v1, v2)\n",
    "            F = X ** 2 + Y ** 2 - ((RAY / 6) * (i + 1)) ** 2\n",
    "\n",
    "            ax.contour(X, Y, F, [0], colors=\"k\", linestyles=\"dashed\", linewidths=1)\n",
    "        ax.set_aspect(1)\n",
    "        plt.show()\n",
    "\n",
    "    return NODES\n",
    "\n",
    "\n",
    "# SF Allocation Display\n",
    "\n",
    "# RA-Lora Plot\n",
    "def SF_alloc_plot(sorted_nodes, exp, k, display=False, save=False):\n",
    "    groups = []\n",
    "    for s in range(7, 13):\n",
    "        group = []\n",
    "        posx = []\n",
    "        posy = []\n",
    "        for n in sorted_nodes:\n",
    "            if n.sf == s:\n",
    "                posx.append(n.x)\n",
    "                posy.append(n.y)\n",
    "\n",
    "        group.append(posx)\n",
    "        group.append(posy)\n",
    "        groups.append(group)\n",
    "        group = []\n",
    "    # print(groups)\n",
    "    colors = [\"ro\", \"go\", \"bo\", \"yo\", \"co\", \"mo\"]\n",
    "    # print(len(groups[3][0]))\n",
    "    # print(len(groups[3][1]))\n",
    "    fig, ax = plt.subplots()\n",
    "    for g, c in zip(groups, colors):\n",
    "        ax.plot(g[0], g[1], c)\n",
    "\n",
    "    ax.plot(0, 0, \"ko\")\n",
    "\n",
    "    for i in range(6):\n",
    "        v1 = np.linspace((-RAY / 6) * (i + 1), (RAY / 6) * (i + 1), 100)\n",
    "        v2 = np.linspace((-RAY / 6) * (i + 1), (RAY / 6) * (i + 1), 100)\n",
    "        X, Y = np.meshgrid(v1, v2)\n",
    "        F = X ** 2 + Y ** 2 - ((RAY / 6) * (i + 1)) ** 2\n",
    "\n",
    "        ax.contour(X, Y, F, [0], colors=\"k\", linestyles=\"dashed\", linewidths=1)\n",
    "    ax.set_aspect(1)\n",
    "    if save:\n",
    "        if not os.path.exists(\"reports/graphics/{}\".format(exp)):\n",
    "            os.mkdir(\"reports/graphics/{}\".format(exp))\n",
    "        plt.savefig(\"reports/graphics/{}/sf_alloc_{}\".format(exp, k))\n",
    "    if display:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "def finalReport(data):\n",
    "    fname = \"sim_results-v2-1.csv\"\n",
    "    if not os.path.isfile(\"reports/results/{}\".format(fname)):\n",
    "        df_new = pd.DataFrame(data, index=[0])\n",
    "        df_new.to_csv(\"reports/results/{}\".format(fname), index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(\"reports/results/{}\".format(fname))\n",
    "        df_new = pd.DataFrame(data, index=[df.ndim - 1])\n",
    "        df = df.append(df_new, ignore_index=True)\n",
    "        df.to_csv(\"reports/results/{}\".format(fname), index=False)\n",
    "\n",
    "\n",
    "def airtime(sf, cr, pl, bw):\n",
    "    H = 0  # implicit header disabled (H=0) or not (H=1)\n",
    "    DE = 0  # low data rate optimization enabled (=1) or not (=0)\n",
    "    Npream = 8  # number of preamble symbol (12.25  from Utz paper)\n",
    "\n",
    "    if bw == 125 and sf in [11, 12]:\n",
    "        # low data rate optimization mandated for BW125 with SF11 and SF12\n",
    "        DE = 1\n",
    "    if sf == 6:\n",
    "        # can only have implicit header with SF6\n",
    "        H = 1\n",
    "    Tsym = (2.0 ** sf) / bw  # msec\n",
    "    Tpream = (Npream + 4.25) * Tsym\n",
    "    # print \"sf\", sf, \" cr\", cr, \"pl\", pl, \"bw\", bw\n",
    "    payloadSymbNB = 8 + max(\n",
    "        math.ceil((8.0 * pl - 4.0 * sf + 28 + 16 - 20 * H) / (4.0 * (sf - 2 * DE)))\n",
    "        * (cr + 4),\n",
    "        0,\n",
    "    )\n",
    "    Tpayload = payloadSymbNB * Tsym\n",
    "    return (Tpream + Tpayload) / 1000.0  # in seconds\n",
    "        \n",
    "        \n",
    "def mathematical_model(N, sf_dist, avgtime):\n",
    "    charges = []\n",
    "    DERs = []\n",
    "    s = 0\n",
    "    for i in range(6):\n",
    "        Nsf = sf_dist[i]\n",
    "        toa = airtime(i + 7, 1, packetlen, BW)\n",
    "        c = (Nsf * toa) / avgtime\n",
    "        charges.append(c)\n",
    "        DERsf = math.exp(-2*c)\n",
    "        DERs.append(DERsf)\n",
    "        s = s + (DERsf * Nsf)\n",
    "    DER = s / N\n",
    "    return DER, DERs, charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Environment(gym.Env):\n",
    "    def __init__(self, nodes, SF_dist_init, Ch_dist_init):\n",
    "\n",
    "        \"\"\" Environment Parameter\"\"\"\n",
    "\n",
    "        super(Environment, self).__init__()\n",
    "\n",
    "        self.NODES = nodes\n",
    "        self.N = len(self.NODES)\n",
    "        self.TP_SET = [2, 5, 8, 11, 14]\n",
    "        self.SF_SET = [7, 8, 9, 10, 11, 12]\n",
    "        self.CH_SET = [\"868.1\", \"868.3\", \"868.5\"]\n",
    "        self.ACTION_SPACE_GEN = self.action_space_generator()\n",
    "        self.ACTION_SPACE_SIZE = len(self.ACTION_SPACE_GEN)\n",
    "        self.STATE_SPACE = []\n",
    "        self.SF_DIST = SF_dist_init\n",
    "        self.ENERGY = 1\n",
    "        self.CH_DIST = Ch_dist_init\n",
    "\n",
    "        \"\"\" Simulation Parameters\"\"\"\n",
    "        self.action_space = spaces.Box(\n",
    "            np.array([0,7, 0, 0]), np.array([self.N - 1,12, 4, 2]), dtype=np.int32\n",
    "        )\n",
    "        # self.observation_space = spaces.Box(np.array([0,7,0,0,-10,-135]), np.array([N,12,4,2,10,-70]),dtype =np.int)\n",
    "        self.observation_space = spaces.Box(\n",
    "            np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
    "            np.array(\n",
    "                [\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                    self.N,\n",
    "                ]\n",
    "            ),\n",
    "            dtype=np.int32,\n",
    "        )\n",
    "        self.condition = 0\n",
    "\n",
    "    def action_space_generator(self):\n",
    "        action_space = []\n",
    "\n",
    "        for n in range(self.N):\n",
    "\n",
    "            for sf in self.SF_SET:\n",
    "\n",
    "                for tp in range(len(self.TP_SET)):\n",
    "\n",
    "                    for ch in range(len(self.CH_SET)):\n",
    "                        action_space.append([n, sf, tp, ch])\n",
    "        return action_space\n",
    "\n",
    "    def toa(self, sf, cr, pl, bw):\n",
    "        H = 0  # implicit header disabled (H=0) or not (H=1)\n",
    "        DE = 0  # low data rate optimization enabled (=1) or not (=0)\n",
    "        Npream = 8  # number of preamble symbol (12.25  from Utz paper)\n",
    "\n",
    "        if bw == 125 and sf in [11, 12]:\n",
    "            # low data rate optimization mandated for BW125 with SF11 and SF12\n",
    "            DE = 1\n",
    "        if sf == 6:\n",
    "            # can only have implicit header with SF6\n",
    "            H = 1\n",
    "        Tsym = (2.0 ** sf) / bw  # msec\n",
    "        Tpream = (Npream + 4.25) * Tsym\n",
    "        # print \"sf\", sf, \" cr\", cr, \"pl\", pl, \"bw\", bw\n",
    "        payloadSymbNB = 8 + max(\n",
    "            math.ceil((8.0 * pl - 4.0 * sf + 28 + 16 - 20 * H) / (4.0 * (sf - 2 * DE)))\n",
    "            * (cr + 4),\n",
    "            0,\n",
    "        )\n",
    "        Tpayload = payloadSymbNB * Tsym\n",
    "        return (Tpream + Tpayload) / 1000.0  # in seconds\n",
    "\n",
    "    def rho_compute(self, sf, n):\n",
    "        return (self.toa(sf, CR, PL, BW) * n) / p\n",
    "\n",
    "    def reward_function(self, rho, u_ch, tp):\n",
    "        return (rho_max) / (rho * u_ch) + ((tp_max - tp) / (tp_max - tp_min))\n",
    "\n",
    "    def reward_function_zero(self, tp):\n",
    "        return (tp_max - tp) / (tp_max - tp_min)\n",
    "\n",
    "    def compute_der(self, sf_dist):\n",
    "        der = 0\n",
    "        for index in range(len(sf_dist)):\n",
    "            rho = self.rho_compute(self.SF_SET[index], sf_dist[index])\n",
    "            der_sf = math.exp(-2 * rho)\n",
    "            der = der + (der_sf * sf_dist[index])\n",
    "        return (der / self.N) * 100\n",
    "\n",
    "    def reset(self):\n",
    "        sf_dist, tp_dist, u_ch = compute_sf_ch_utilization(self.NODES)\n",
    "        state = np.concatenate((sf_dist, tp_dist, u_ch))\n",
    "        self.condition = 0\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        # print('Step : ',self.condition)\n",
    "        # print('Action : ',action)\n",
    "        # assert self.action_space.contains(action)\n",
    "        reward = 0\n",
    "        #node_index = random.randint(0,self.N-1)\n",
    "        node_index = action[0]\n",
    "        node = self.NODES[node_index]\n",
    "        old_sf = node.sf\n",
    "        old_tp = node.tx\n",
    "        old_ch = node.freq\n",
    "        new_sf = action[1]\n",
    "        new_tp = self.TP_SET[action[2]]\n",
    "        new_ch = action[3]\n",
    "\n",
    "        sf_dist, tp_dist, u_ch = compute_sf_ch_utilization(self.NODES)\n",
    "        der = self.compute_der(sf_dist)\n",
    "        #print(\"DER : \", der)\n",
    "        config = config_dict[new_sf - 7]\n",
    "        # print(\"config : \", config)\n",
    "        \n",
    "        # print('rho',rho)\n",
    "        # print(\"node snr : {} rssi : {}\".format(node.snr, node.rssi))\n",
    "        # print(\"node old sf : {} new sf: {}\".format(old_sf, new_sf))\n",
    "        if node.snr < config[\"snr\"] or node.rssi < config[\"sens\"]:\n",
    "             \n",
    "            #rho = self.rho_compute(new_sf, sf_dist[new_sf - 7])\n",
    "            #if rho > 0 and u_ch[new_ch] > 0:\n",
    "                #reward = - self.reward_function(rho, u_ch[new_ch], new_tp)\n",
    "            #else:\n",
    "                #reward = - self.reward_function_zero(new_tp)\n",
    "            reward = -1\n",
    "\n",
    "        else: \n",
    "            rho = self.rho_compute(new_sf, sf_dist[new_sf - 7])\n",
    "            old_rho = self.rho_compute(old_sf, sf_dist[old_sf - 7])\n",
    "            if new_sf > old_sf:\n",
    "                if old_rho > rho_max and rho < rho_max :\n",
    "                    self.NODES[node_index].sf = new_sf\n",
    "                    self.NODES[node_index].freq = ch[new_ch]\n",
    "                    self.NODES[node_index].tx = new_tp\n",
    "                    \n",
    "                    self.NODES[node_index].packet.sf = new_sf\n",
    "                    self.NODES[node_index].packet.freq = ch[new_ch]\n",
    "            \n",
    "                    \n",
    "                    self.NODES[node_index].update_rectime(new_sf)\n",
    "\n",
    "                    sf_dist[old_sf - 7] = sf_dist[old_sf - 7] - 1\n",
    "                    sf_dist[new_sf - 7] = sf_dist[new_sf - 7] + 1\n",
    "\n",
    "                    old_tp_index = self.TP_SET.index(old_tp)\n",
    "                    new_tp_index = self.TP_SET.index(new_tp)\n",
    "                    tp_dist[old_tp_index] = tp_dist[old_tp_index] - 1\n",
    "                    tp_dist[new_tp_index] = tp_dist[new_tp_index] + 1\n",
    "\n",
    "                    old_ch_index = ch.index(old_ch)\n",
    "                    new_ch_index = new_ch\n",
    "                    u_ch[old_ch_index] = u_ch[old_ch_index] - 1\n",
    "                    u_ch[new_ch_index] = u_ch[new_ch_index] + 1\n",
    "            else:\n",
    "                \n",
    "                self.NODES[node_index].sf = new_sf\n",
    "                self.NODES[node_index].freq = ch[new_ch]\n",
    "                self.NODES[node_index].tx = new_tp\n",
    "                self.NODES[node_index].update_rectime(new_sf)\n",
    "                \n",
    "                self.NODES[node_index].packet.sf = new_sf\n",
    "                self.NODES[node_index].packet.freq = ch[new_ch]\n",
    "\n",
    "                sf_dist[old_sf - 7] = sf_dist[old_sf - 7] - 1\n",
    "                sf_dist[new_sf - 7] = sf_dist[new_sf - 7] + 1\n",
    "\n",
    "                old_tp_index = self.TP_SET.index(old_tp)\n",
    "                new_tp_index = self.TP_SET.index(new_tp)\n",
    "                tp_dist[old_tp_index] = tp_dist[old_tp_index] - 1\n",
    "                tp_dist[new_tp_index] = tp_dist[new_tp_index] + 1\n",
    "\n",
    "                old_ch_index = ch.index(old_ch)\n",
    "                new_ch_index = new_ch\n",
    "                u_ch[old_ch_index] = u_ch[old_ch_index] - 1\n",
    "                u_ch[new_ch_index] = u_ch[new_ch_index] + 1\n",
    "        \n",
    "\n",
    "            if rho > 0 and u_ch[new_ch] > 0:\n",
    "                reward = self.reward_function(rho, u_ch[new_ch], new_tp)\n",
    "            else:\n",
    "                reward = self.reward_function_zero(new_tp)\n",
    "\n",
    "           \n",
    "        # print(sf_dist)\n",
    "        # print(tp_dist)\n",
    "        # print(u_ch)\n",
    "\n",
    "        # print('Reward = ',reward)\n",
    "        new_state = np.concatenate((sf_dist, tp_dist, u_ch))\n",
    "        # print('')\n",
    "        done = False\n",
    "        self.condition = self.condition + 1\n",
    "        if self.condition == 100:\n",
    "            done = True\n",
    "        #if der > 95:\n",
    "            #done = True\n",
    "\n",
    "        info = \"\"\n",
    "\n",
    "        return new_state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_nodes (nodes,file_name):\n",
    "    pickle.dump(nodes, open(\"data/\"+file_name, \"wb\"))\n",
    "    print('All Nodes Were Saved !')\n",
    "    \n",
    "def load_nodes (file_name):\n",
    "    print('Loading Nodes From File')\n",
    "    nodes = pickle.load(open(\"data/\"+file_name,\"rb\"))\n",
    "    return nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Nodes Were Saved !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nodes = node_Gen(5000, display=False)\n",
    "nodes, sf_distribution, ch_u = SF_alloc_ch_utilization(nodes)\n",
    "save_nodes(nodes,'nodes_{}.alloc'.format(len(nodes)))\n",
    "#train_episodes = 300\n",
    "#test_episodes = 100\n",
    "\n",
    "train_episodes = 300\n",
    "test_episodes = 100\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    def create_model(self, action_shape, state_shape):\n",
    "        model = Sequential()\n",
    "        learning_rate = 0.001\n",
    "        init = tf.keras.initializers.HeUniform()\n",
    "\n",
    "        model.add(\n",
    "            Dense(\n",
    "                256, input_shape=state_shape, activation=\"relu\", kernel_initializer=init\n",
    "            )\n",
    "        )\n",
    "        model.add(Dense(256, activation=\"relu\", kernel_initializer=init))\n",
    "\n",
    "        model.add(Dense(450000, activation=\"relu\", kernel_initializer=init))\n",
    "\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.Huber(),\n",
    "            optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        model.save('lora_rl_model.h5')\n",
    "        return model\n",
    "\n",
    "    def get_qs(self, model, state, step):\n",
    "        return model.predict(state.reshape([1, state.shape[0]]))[0]\n",
    "\n",
    "    def train(self, env, replay_memory, model, target_model, done):\n",
    "        learning_rate = 0.7  # Learning rate\n",
    "        discount_factor = 0.618\n",
    "\n",
    "        MIN_REPLAY_SIZE = 1000\n",
    "        if len(replay_memory) < MIN_REPLAY_SIZE:\n",
    "            return\n",
    "\n",
    "        batch_size = 64 * 2\n",
    "        mini_batch = random.sample(replay_memory, batch_size)\n",
    "        # print(len(mini_batch))\n",
    "        # print(mini_batch)\n",
    "\n",
    "        # current_states = np.array([transition[0] for transition in mini_batch],dtype=object)\n",
    "        # print()\n",
    "        current_states = np.array(\n",
    "            np.array(\n",
    "                [\n",
    "                    transition[0]\n",
    "                    for transition in mini_batch\n",
    "                    if transition[0] is not None\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        # print('states len : ',len(current_states))\n",
    "        # current_states= np.array(current_states).astype(\"float32\")\n",
    "        # print(current_states)\n",
    "        # current_states = np.asarray(current_states).astype(np.float32)\n",
    "        current_qs_list = model.predict(current_states)\n",
    "        # print(current_qs_list)\n",
    "        # print('Current: ',len(current_qs_list))\n",
    "        # print('Mini batch : ',len(mini_batch))\n",
    "        new_current_states = np.array(\n",
    "            [transition[3] for transition in mini_batch if transition[3] is not None]\n",
    "        )\n",
    "        future_qs_list = target_model.predict(new_current_states)\n",
    "        # print()\n",
    "\n",
    "        X = []\n",
    "        Y = []\n",
    "        #print(mini_batch)\n",
    "        #print(len(mini_batch))\n",
    "        for index, (observation, action, reward, new_observation, done) in enumerate(\n",
    "            mini_batch\n",
    "        ):\n",
    "            if not done:\n",
    "                max_future_q = reward + discount_factor * np.max(future_qs_list[index])\n",
    "            else:\n",
    "                max_future_q = reward\n",
    "\n",
    "            current_qs = current_qs_list[index]\n",
    "            #print('The current_qs : ',current_qs)\n",
    "            #print('Action : ',action)\n",
    "            #print(type(action))\n",
    "            #print(env.ACTION_SPACE_GEN)\n",
    "            action_index = env.ACTION_SPACE_GEN.index(action)\n",
    "            current_qs[action_index] = (1 - learning_rate) * current_qs[\n",
    "                action_index\n",
    "            ] + learning_rate * max_future_q\n",
    "\n",
    "            X.append(observation)\n",
    "            Y.append(current_qs)\n",
    "        model.fit(\n",
    "            np.array(X), np.array(Y), batch_size=batch_size, verbose=0, shuffle=True\n",
    "        )\n",
    "\n",
    "\n",
    "env = Environment(nodes, sf_distribution, ch_u)\n",
    "\n",
    "\n",
    "agent = DQNAgent()\n",
    "\n",
    "\n",
    "# agent.train()\n",
    "\n",
    "\n",
    "def main():\n",
    "    epsilon = 1  # Epsilon-greedy algorithm in initialized at 1 meaning every step is random at the start\n",
    "    max_epsilon = 1  # You can't explore more than 100% of the time\n",
    "    min_epsilon = 0.01  # At a minimum, we'll always explore 1% of the time\n",
    "    decay = 0.01\n",
    "    final_rewards = []\n",
    "    # 1. Initialize the Target and Main models\n",
    "    # Main Model (updated every 4 steps)\n",
    "    print(env.observation_space.shape)\n",
    "    print(env.action_space.shape)\n",
    "    #print_nodes(nodes)\n",
    "    #SF_alloc_plot(nodes,10,5,display=True)\n",
    "    model = agent.create_model(env.action_space.shape, env.observation_space.shape)\n",
    "    print(\"Model Created !\")\n",
    "    # Target Model (updated every 100 steps)\n",
    "    target_model = agent.create_model(\n",
    "        env.action_space.shape, env.observation_space.shape\n",
    "    )\n",
    "    print(\"Target Model Created !\")\n",
    "    target_model.set_weights(model.get_weights())\n",
    "\n",
    "    replay_memory = deque(maxlen=50_000)\n",
    "\n",
    "    target_update_counter = 0\n",
    "\n",
    "    # X = states, y = actions\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    steps_to_update_target_model = 0\n",
    "\n",
    "    for episode in range(train_episodes):\n",
    "        print('Episode : ',episode)\n",
    "        total_training_rewards = 0\n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            steps_to_update_target_model += 1\n",
    "            # if True:\n",
    "            # env.render()\n",
    "\n",
    "            random_number = np.random.rand()\n",
    "            # 2. Explore using the Epsilon Greedy Exploration Strategy\n",
    "            if random_number <= epsilon:\n",
    "                # Explore\n",
    "                # print('Explore')\n",
    "                action = env.action_space.sample()\n",
    "                a =[]\n",
    "                a.append(action[0])\n",
    "                a.append(action[1])\n",
    "                a.append(action[2])\n",
    "                a.append(action[3])\n",
    "                action = a\n",
    "            else:\n",
    "\n",
    "                # Exploit best known action\n",
    "                # model dims are (batch, env.observation_space.n)\n",
    "                # print('Exploit')\n",
    "                encoded = observation\n",
    "                encoded_reshaped = encoded.reshape([1, encoded.shape[0]])\n",
    "                # print('model : ',model)\n",
    "                # print('Encoded state : ',encoded_reshaped)\n",
    "                predicted = model.predict(encoded_reshaped)\n",
    "                action = np.argmax(predicted)\n",
    "                action = env.ACTION_SPACE_GEN[action]\n",
    "            #print(action)\n",
    "            #print(type(action))\n",
    "            new_observation, reward, done, info = env.step(action)\n",
    "            replay_memory.append([observation, action, reward, new_observation, done])\n",
    "\n",
    "            # 3. Update the Main Network using the Bellman Equation\n",
    "            if steps_to_update_target_model % 4 == 0 or done:\n",
    "                agent.train(env, replay_memory, model, target_model, done)\n",
    "\n",
    "            observation = new_observation\n",
    "            total_training_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                print(\n",
    "                    \"Total training rewards: {} after n steps = {} with final reward = {}\".format(\n",
    "                        total_training_rewards, episode, reward\n",
    "                    )\n",
    "                )\n",
    "                final_rewards.append(total_training_rewards)\n",
    "                total_training_rewards += 1\n",
    "\n",
    "                if steps_to_update_target_model >= 100:\n",
    "                    print(\"Copying main network weights to the target network weights\")\n",
    "                    target_model.set_weights(model.get_weights())\n",
    "                    steps_to_update_target_model = 0\n",
    "                break\n",
    "\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * episode)\n",
    "        #SF_alloc_plot(nodes,10,5,display=True)\n",
    "    env.close()\n",
    "    save_nodes(env.NODES,'nodes_{}.rl'.format(len(env.NODES)))\n",
    "    #print_nodes(env.NODES)\n",
    "    print(final_rewards)\n",
    "    #print_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "(4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhamnache/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created !\n",
      "Target Model Created !\n",
      "Episode :  0\n",
      "Total training rewards: 33.994493915784226 after n steps = 0 with final reward = 0.5014274230691593\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  1\n",
      "Total training rewards: 32.84614918880318 after n steps = 1 with final reward = 0.7602185093336682\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f61a42b4830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f61a42b4830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Total training rewards: 17.014679252071453 after n steps = 2 with final reward = 0.753882606067944\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  3\n",
      "Total training rewards: 29.211023853109243 after n steps = 3 with final reward = 0.7535056135286603\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  4\n",
      "Total training rewards: 18.963264578842814 after n steps = 4 with final reward = 0.253063696014637\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  5\n",
      "Total training rewards: 23.946199322845466 after n steps = 5 with final reward = 0.2503062615473442\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  6\n",
      "Total training rewards: 11.885684397268344 after n steps = 6 with final reward = 1.004328765186278\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  7\n",
      "Total training rewards: 28.140455921842303 after n steps = 7 with final reward = 0.5021216900494608\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  8\n",
      "Total training rewards: 30.360225543594712 after n steps = 8 with final reward = 1.0010185758473675\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  9\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f61a4074290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f61a4074290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f61a4173290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f61a4173290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Total training rewards: 24.88901198261974 after n steps = 9 with final reward = 0.5009273491912399\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  10\n",
      "Total training rewards: 34.898379194289106 after n steps = 10 with final reward = 0.0009058550761741504\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  11\n",
      "Total training rewards: 32.878104961311955 after n steps = 11 with final reward = 0.5003318832521066\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  12\n",
      "Total training rewards: 36.87340899118245 after n steps = 12 with final reward = 1.0013875829377636\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  13\n",
      "Total training rewards: 35.13287149527196 after n steps = 13 with final reward = 1.0008372542445259\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  14\n",
      "Total training rewards: 23.114822128995435 after n steps = 14 with final reward = 0.0011462932200596576\n",
      "Copying main network weights to the target network weights\n",
      "Episode :  15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-8c96ab2c43a4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;31m# 3. Update the Main Network using the Bellman Equation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msteps_to_update_target_model\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplay_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8c96ab2c43a4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, env, replay_memory, model, target_model, done)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m#print(type(action))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m#print(env.ACTION_SPACE_GEN)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0maction_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACTION_SPACE_GEN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             current_qs[action_index] = (1 - learning_rate) * current_qs[\n\u001b[1;32m     94\u001b[0m                 \u001b[0maction_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_names = ['nodes_5000.alloc','nodes_5000.rl']\n",
    "for i in range (2):\n",
    "    file_name = file_names [i]\n",
    "    nodes = load_nodes(file_name)\n",
    "    sf_distribution, tp_dist, u_ch = compute_sf_ch_utilization(nodes)\n",
    "    def transmit(env, node):\n",
    "\n",
    "        \"\"\"transmit\n",
    "\n",
    "        Parameters\n",
    "                #print (\"frequency coll 125\")\n",
    "        ----------\n",
    "            env : simpy.core.environment\n",
    "            node\n",
    "        \"\"\"\n",
    "        while True:\n",
    "\n",
    "            r = random.expovariate(1.0 / float(AVGSENDTIME))\n",
    "            # r = random.expovariate(1.0 / float(avg_gen(node, AVGSENDTIME)))\n",
    "            # node.freq = random.choice(ch)\n",
    "            # node.packet.freq =node.freq\n",
    "            # get_next_ch(node)\n",
    "            # print('duty cycle : ',r-(node.rectime*99))\n",
    "            # if (r-(node.rectime*99) < 0):\n",
    "            # r = node.rectime*99\n",
    "            yield env.timeout(r)\n",
    "            \"\"\"print(\n",
    "                \"Node-ID :{} SF :{} TX :{} Channel:{}  \".format(\n",
    "                    node.id, node.sf, node.tx, node.freq\n",
    "                )\n",
    "            )\"\"\"\n",
    "            node.sent = node.sent + 1\n",
    "            if node in packetsAtBS:\n",
    "                print(\"ERROR: packet already in\")\n",
    "            else:\n",
    "                sensitivity = config_dict[node.sf - 7][\"sens\"]\n",
    "                # print(\"node id: {} sf :{} s: {} \".format(node.id,node.sf,sensitivity))\n",
    "                if node.packet.rssi < sensitivity:\n",
    "                    node.packet.lost = True\n",
    "                else:\n",
    "                    node.packet.lost = False\n",
    "                    if (\n",
    "                        checkcollision(\n",
    "                            env,\n",
    "                            node.packet,\n",
    "                            packetsAtBS,\n",
    "                            maxBSReceives,\n",
    "                            full_collision,\n",
    "                        )\n",
    "                        == 1\n",
    "                    ):\n",
    "                        node.packet.collided = 1\n",
    "                    else:\n",
    "                        node.packet.collided = 0\n",
    "                        node.received = node.received + 1\n",
    "                    packetsAtBS.append(node)\n",
    "                    node.packet.addTime = env.now\n",
    "            # print('rectime : ',node.packet.rectime)\n",
    "            yield env.timeout(node.packet.rectime)\n",
    "\n",
    "            if node.packet.lost:\n",
    "                global nrLost\n",
    "                nrLost += 1\n",
    "            if node.packet.collided == 1:\n",
    "                global nrCollisions\n",
    "                nrCollisions = nrCollisions + 1\n",
    "            if not node.packet.collided and not node.packet.lost:\n",
    "                global nrReceived\n",
    "                nrReceived = nrReceived + 1\n",
    "            if node.packet.processed == 1:\n",
    "                global nrProcessed\n",
    "                nrProcessed = nrProcessed + 1\n",
    "            if node in packetsAtBS:\n",
    "                packetsAtBS.remove(node)\n",
    "                # reset the packet\n",
    "            node.packet.collided = 0\n",
    "            node.packet.processed = 0\n",
    "            node.packet.lost = False\n",
    "\n",
    "    MODEL = 6\n",
    "    packetsAtBS = []\n",
    "    sim_env = simpy.Environment()\n",
    "    bsId = 1   \n",
    "    maxBSReceives = 8\n",
    "    nrCollisions = 0\n",
    "    nrReceived = 0\n",
    "    nrProcessed = 0\n",
    "    nrLost = 0\n",
    "    full_collision = 1\n",
    "    # AVGSENDTIME = 800\n",
    "    simtime = 7200\n",
    "    # print(NODES)\n",
    "    for n in nodes:\n",
    "        # print(n.packet)\n",
    "        sim_env.process(transmit(sim_env, n))\n",
    "    print(\"Simulation Started\")\n",
    "    sim_env.run(until=simtime)\n",
    "    print(\"Simulation Finished\")\n",
    "\n",
    "    sent = sum(n.sent for n in nodes)\n",
    "    energy = (\n",
    "        sum(\n",
    "            node.packet.rectime * TX[int(node.tx) + 2] * 3 * node.sent\n",
    "            for node in nodes\n",
    "        )\n",
    "        / 1e6\n",
    "    )\n",
    "\n",
    "    print(\"Sent :\", sent)\n",
    "    print(\"Collisions :\", nrCollisions)\n",
    "    print(\"Received :\", nrReceived)\n",
    "    print(\"Processed :\", nrProcessed)\n",
    "\n",
    "    print(\"Loss : \", nrLost)\n",
    "    # print(energy)\n",
    "    der1 = (float(nrReceived) / float(sent)) * 100 if sent != 0 else 0\n",
    "    print(\"DER1 : {:.2f} %\".format(der1))\n",
    "    der2 = (float(sent - nrCollisions) / float(sent)) * 100 if sent != 0 else 0\n",
    "    print(\"DER2 : {:.2f} %\".format(der2))\n",
    "    print(\"Energy : {} J\".format(energy))\n",
    "\n",
    "    DER, DERs, charges = mathematical_model(\n",
    "        len(nodes), sf_distribution, AVGSENDTIME\n",
    "    )\n",
    "    print(charges)\n",
    "    DER = DER * 100\n",
    "    print(\"DER ==>\", DER)\n",
    "    print(DERs)\n",
    "    print(charges)\n",
    "    error = abs(DER - der1)\n",
    "    print(\"Error : {:.2f}\".format(error))\n",
    "\n",
    "    data = {\n",
    "        \"Experience\": 1,\n",
    "        \"Rho_max\":rho_max,\n",
    "        \"Packet_generation\":p,\n",
    "        \"Nodes\": len(nodes),\n",
    "        \"PathLoss\": MODEL,\n",
    "        \"Packet_Sent\": sent,\n",
    "        \"Packet_Loss\": nrLost,\n",
    "        \"Collisions\": nrCollisions,\n",
    "        \"Energy\": energy,\n",
    "        \"DER\": der1,\n",
    "        \"Mathematical-Model\": DER,\n",
    "        \"Error\": error,\n",
    "        \"SF7\": charges[0],\n",
    "        \"SF8\": charges[1],\n",
    "        \"SF9\": charges[2],\n",
    "        \"SF10\": charges[3],\n",
    "        \"SF11\": charges[4],\n",
    "        \"SF12\": charges[5],\n",
    "        \"DSF7\": sf_distribution[0],\n",
    "        \"DSF8\": sf_distribution[1],\n",
    "        \"DSF9\": sf_distribution[2],\n",
    "        \"DSF10\": sf_distribution[3],\n",
    "        \"DSF11\": sf_distribution[4],\n",
    "        \"DSF12\": sf_distribution[5],\n",
    "       }\n",
    "\n",
    "    finalReport(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devices = load_nodes('nodes_1000.alloc')\n",
    "#print_nodes(devices)\n",
    "#model = agent.create_model(env.action_space.shape, env.observation_space.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
